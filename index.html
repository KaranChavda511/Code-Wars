<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Voice Interaction with Gemini (Free TTS)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap"
      rel="stylesheet"
    />
    <style>
      body {
        font-family: "Inter", sans-serif;
      }
      #scrib {
        padding: 1rem;
        border: 1px solid #e2e8f0;
        margin-bottom: 1rem;
        border-radius: 0.5rem;
        background-color: #f7fafc;
        min-height: 2.5rem;
        white-space: pre-wrap;
      }
      .button {
        padding: 0.75rem 1.5rem;
        border-radius: 0.375rem;
        font-weight: 600;
        cursor: pointer;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        transition: transform 0.2s ease, box-shadow 0.2s ease,
          background-color 0.3s;
        display: inline-flex;
        align-items: center;
        justify-content: center;
        gap: 0.5rem;
      }
      .button:hover {
        transform: translateY(-2px) scale(1.05);
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
      }
      .button:active {
        transform: translateY(0) scale(0.95);
        box-shadow: 0 1px 2px rgba(0, 0, 0, 0.2);
      }
      .primary-button {
        background-color: #6366f1;
        color: white;
      }
      .primary-button:hover {
        background-color: #4338ca;
      }
      .secondary-button {
        background-color: #e5e7eb;
        color: #374151;
      }
      .secondary-button:hover {
        background-color: #d1d5db;
      }
      #audio {
        display: none;
      }
    </style>
  </head>
  <body class="bg-gray-100 p-4">
    <div class="container mx-auto p-6 bg-white rounded-lg shadow-md">
      <h1 class="text-2xl font-semibold text-gray-800 mb-4">
        Voice Interaction with Gemini (Free TTS)
      </h1>
      <div id="scrib" class="text-gray-700 mb-4"></div>
      <button id="startBtn" class="button primary-button">
        <svg
          xmlns="http://www.w3.org/2000/svg"
          width="24"
          height="24"
          viewBox="0 0 24 24"
          fill="none"
          stroke="currentColor"
          stroke-width="2"
          stroke-linecap="round"
          stroke-linejoin="round"
          class="lucide lucide-mic"
        >
          <path
            d="M12 17c-1.333 0-4-2.667-4-8v-3c0-5.333 2.667-8 8-8s8 2.667 8 8v3c0 5.333-2.667 8-4 8z"
          />
          <path d="M9 17v-4c0-1.333.667-2 2-2s2 .667 2 2v4" />
          <path d="M12 19c1.333 0 4 2.667 4 8h-8c0-5.333 2.667-8 4-8z" />
        </svg>
        Start Listening
      </button>
      <audio id="audio"></audio>
    </div>
 
    <script>
      const SpeechRecognition =
        window.SpeechRecognition || window.webkitSpeechRecognition;
 
      if (!SpeechRecognition) {
        console.error("SpeechRecognition is not supported in this browser.");
        document.getElementById("scrib").textContent =
          "Speech recognition is not supported in your browser. Try using Chrome.";
        document.getElementById("startBtn").disabled = true;
      } else {
        let r = new SpeechRecognition();
        r.continuous = false;
        r.interimResults = false;
        r.maxAlternatives = 1;
 
        r.onstart = function () {
          console.log("Speech recognition started");
          scrib.show("Listening...");
          document.getElementById("startBtn").textContent = "Listening....";
          document
            .getElementById("startBtn")
            .classList.remove("primary-button");
          document.getElementById("startBtn").classList.add("secondary-button");
        };
 
        r.onend = function () {
          console.log("Speech recognition ended");
          document.getElementById("startBtn").textContent = "Start Listening";
          document.getElementById("startBtn").classList.add("primary-button");
          document
            .getElementById("startBtn")
            .classList.remove("secondary-button");
        };
 
        r.onresult = async function (event) {
          const transcript = event.results[0][0].transcript;
          console.log("Transcript:", transcript);
          scrib.show(`You said: ${transcript}`);
          try {
            const result = await callGemini(transcript);
            console.log("Gemini Response:", result);
            if (
              result &&
              result.candidates &&
              result.candidates[0] &&
              result.candidates[0].content &&
              result.candidates[0].content.parts &&
              result.candidates[0].content.parts[0]
            ) {
              const text = result.candidates[0].content.parts[0].text;
              scrib.show(`Optimus Ai says: ${text}`);
              speak(text);
            } else {
              scrib.show("Sorry, I didn't get a valid response from Gemini.");
            }
          } catch (error) {
            console.error("Error calling Gemini:", error);
            scrib.show(
              `Error: ${error.message || "Failed to process your request."}`
            );
          }
          r.stop();
        };
 
        r.onerror = function (event) {
          console.error("Speech recognition error:", event.error);
          scrib.show(`Error: ${event.error}`);
          r.stop();
        };
 
        document
          .getElementById("startBtn")
          .addEventListener("click", function () {
            if (r.state !== "listening") {
              r.start();
            } else {
              console.log("Speech recognition is already in progress.");
            }
          });
      }
 
      const scrib = {
        show: (text) => {
          const scribDiv = document.getElementById("scrib");
          scribDiv.textContent = text;
        },
      };
 
      async function callGemini(text) {
        const body = {
          system_instruction: {
            parts: [
              {
                text: "You are an AI assistant of Karan Chavda. Reply in short sentences with emotions, suitable for speaking.",
              },
            ],
          },
          contents: [
            {
              parts: [{ text: text }],
            },
          ],
        };
 
        const API_KEY = "YOUR_GEMINI_KEY"; // Replace if needed
 
        const response = await fetch(
          `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${API_KEY}`,
          {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(body),
          }
        );
 
        if (!response.ok) {
          const errorText = await response.text();
          throw new Error(
            `Gemini API error: ${response.status} - ${errorText}`
          );
        }
 
        return await response.json();
      }
 
      function speak(text) {
        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = "hi-IN";
        utterance.pitch = 1.1;
        utterance.rate = 1;
        utterance.volume = 1;
 
        // Optional: Select a specific voice
        const voices = speechSynthesis.getVoices();
        console.log(voices)
        const preferred = voices.find(
          (v) => v.name.includes("Google हिन्दी")
        );
        if (preferred) {
          utterance.voice = preferred;
        }
 
        speechSynthesis.speak(utterance);
      }
 
      // Load voices before using
      speechSynthesis.onvoiceschanged = () => {
        speechSynthesis.getVoices();
      };
    </script>
  </body>
</html>
 
 